# **Improved Inverse Q-Learning (IQ-Learn)**  

This is an **improved version** of [IQ-Learn](https://arxiv.org/abs/2106.12142), originally proposed in **NeurIPS 2021**.  
Our modifications include:  

- ‚úÖ **Added KL divergence and reward-based baselines**  
- ‚úÖ **Extended support for Gym Atari and MuJoCo environments**  
- ‚úÖ **Optimized training pipeline for better stability**  

### **Original Paper:**  
üìÑ **IQ-Learn: Inverse Soft-Q Learning for Imitation**  
‚û°Ô∏è [**arXiv Link**](https://arxiv.org/abs/2106.12142)  

### **Original Codebase:**  
üñ•Ô∏è [**GitHub Repository**](https://github.com/Div99/IQ-Learn)  

---

## **Introduction**  
IQ-Learn is a **state-of-the-art imitation learning framework** that directly learns soft Q-functions from expert data. Unlike traditional adversarial approaches (e.g., GAIL, AIRL), IQ-Learn provides a **simple, stable, and data-efficient alternative** for both offline and online imitation learning.  

### **Our Key Modifications**  
1Ô∏è‚É£ Introduced **KL divergence** and **reward-based baselines** to improve performance.  
2Ô∏è‚É£ Adapted the method for **Gym Atari and MuJoCo environments**.  
3Ô∏è‚É£ Optimized the **training pipeline** for better efficiency and generalization.  

---

## **Key Advantages**  

‚úîÔ∏è **Drop-in replacement for Behavior Cloning**  
‚úîÔ∏è **Non-adversarial online imitation learning (successor to GAIL & AIRL)**  
‚úîÔ∏è **Performs well with very sparse expert data**  
‚úîÔ∏è **Scales to complex environments (Atari, MuJoCo)**  
‚úîÔ∏è **Can recover reward functions from the environment**  

---

## **Installation & Usage**  

Please refer to the [iq_learn](iq_learn) directory for installation and usage instructions.

---
####if you can't use WANDB,then you may can use
```
$env:WANDB_MODE = "offline"
```

## **Demonstrations**  

### **Imitation Learning on Atari**  
IQ-Learn achieving human-level imitation in various Atari games:  

<p float="left">
<img src="videos/pong.gif" width="250">
<img src="videos/breakout.gif" width="250">
</p>
<p float="left">
<img src="videos/space.gif" width="250">
<img src="videos/qbert.gif" width="250">
</p>

### **Reward Recovery on GridWorld**  
IQ-Learn successfully recovers environment reward functions in GridWorld:  

![Grid](videos/grid.jpg)

---

## **Citing This Work**  
If you use this code, please cite the original **IQ-Learn** paper:  

```
@inproceedings{garg2021iqlearn,
title={IQ-Learn: Inverse soft-Q Learning for Imitation},
author={Divyansh Garg and Shuvam Chakraborty and Chris Cundy and Jiaming Song and Stefano Ermon},
booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
year={2021},
url={https://openreview.net/forum?id=Aeo-xqtb5p}
}
```

---

## **Contact**  
For any questions or discussions, feel free to open an issue or reach out! üöÄ  

---
