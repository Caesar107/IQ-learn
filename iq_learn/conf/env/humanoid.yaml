# @package _global_
#python train_iq.py env=humanoid agent=sac expert.demos=1 method.loss=v0 method.regularize=True agent.actor_lr=3e-05 seed=0 agent.init_temp=1
env:
  name: Humanoid-v2
  demo: Humanoid-v4_expert_trajs
  learn_steps: 1e5
  eval_interval: 1e3

  replay_mem: 1e6
  # initial_mem: 10000

  eps_steps: 100000
  eps_window: 10

expert:
  demos: 64
  subsample_freq: 20

eval:
  policy: 
  threshold: 5000

agent:
  name: sac

log_interval: 500  # Log every this many steps
num_actor_updates: 1

train:
  use_target: true
  soft_update: true
  batch: 256

q_net:
  _target_: agent.sac_models.SingleQCritic