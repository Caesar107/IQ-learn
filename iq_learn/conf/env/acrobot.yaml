# @package _global_
#python train_iq.py agent=softq method=iq env=acrobot expert.demos=64 expert.subsample_freq=4 agent.init_temp=0.001 method.chi=True method.loss=value_expert
env:
  name: Acrobot-v1
  demo: Acrobot_expert_trajs
  learn_steps: 1e5
  eval_interval: 1e3

expert:
  demos: 1
  subsample_freq: 5

eval:
  policy: 
  threshold: 500

q_net:
  _target_: agent.softq_models.OfflineQNetwork